{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Vanilla Neural Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image classifer with logistic regression\n",
    "#images shape(width,height,3(rgb))\n",
    "\n",
    "###to knit to html ipython nbconvert --to html [NEWFILENAME].html\n",
    "import numpy as np\n",
    "import scipy \n",
    "import os\n",
    "import matplotlib.pyplot as plot\n",
    "import math\n",
    "from scipy import ndimage\n",
    "\n",
    "#from basicFunctions import crossEntropyLoss \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossEntropyLoss(a,Y):\n",
    "    num_of_examples = Y.shape[1] #len(Y) doesn't work, need 2nd dimesnion\n",
    "    a = a.T\n",
    "    loss = - (1.0 / num_of_examples) * (np.dot((1 - Y), np.log(1 - a)) + np.dot(Y, np.log(a)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4149316]]\n"
     ]
    }
   ],
   "source": [
    "# Testing cross entropy function\n",
    "test_y = np.asarray([[1,1,1]])\n",
    "test_x = np.asarray([[.8,.9,.4]])\n",
    "print(crossEntropyLoss(test_x,test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output = [1231. 12312. 1231. ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    output = 1.0/(1.0+np.exp(-x))\n",
    "    cached_value = x\n",
    "    cached_value = {\"out_a\":x}\n",
    "    return output, cached_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x,leaky=0):\n",
    "    output = np.maximum(leaky,x)\n",
    "#     cached_value = x\n",
    "    cached_value = {\"out_a\":x}\n",
    "    return output, cached_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To generate numbers randomly with numpy, we will use np.random.randn(dimension_x, dimension_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_params_shallow(input_layer, hidden_layer, output_layer):\n",
    "    w1 = np.random.randn(hidden_layer,input_layer)\n",
    "    w2 = np.random.randn(output_layer,hidden_layer)\n",
    "    #np.random.randn gives numbers larger than 1 so: (vanishing/exploading gradients)\n",
    "    w1,w2 = w1 * .01, w2 * .01\n",
    "    \n",
    "    #is it by one because of broadcasting \n",
    "    b1 = np.zeros((hidden_layer,1))\n",
    "    b2 = np.zeros((output_layer,1))\n",
    "    \n",
    "    assert(w1.shape == (hidden_layer, input_layer))\n",
    "    assert(w2.shape == (output_layer, hidden_layer))\n",
    "    assert(b1.shape == (hidden_layer,1))\n",
    "    assert(b2.shape == (output_layer,1))\n",
    "    \n",
    "    return {\"w1\":w1,\"w2\":w2,\"b1\":b1,\"b2\":b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: [[ 0.01624345 -0.00611756 -0.00528172]\n",
      " [-0.01072969  0.00865408 -0.02301539]\n",
      " [ 0.01744812 -0.00761207  0.00319039]\n",
      " [-0.0024937   0.01462108 -0.02060141]]\n",
      "w2: [[-0.00322417 -0.00384054  0.01133769 -0.01099891]\n",
      " [-0.00172428 -0.00877858  0.00042214  0.00582815]]\n",
      "b1: [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "b2: [[ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "params_shallow = initialize_params_shallow(3, 4, 2)\n",
    "print(\"w1:\", params_shallow[\"w1\"])\n",
    "print(\"w2:\", params_shallow[\"w2\"])\n",
    "print(\"b1:\", params_shallow[\"b1\"])\n",
    "print(\"b2:\", params_shallow[\"b2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test case for initialize_params_shallow using seed(1)\n",
    "##### (3,4,2)\n",
    "<table style:\"width-80%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "         <b> w1:</b> [[ 0.01624345 -0.00611756 -0.00528172]\n",
    "         [-0.01072969  0.00865408 -0.02301539]\n",
    "         [ 0.01744812 -0.00761207  0.00319039]\n",
    "         [-0.0024937   0.01462108 -0.02060141]]\n",
    "        </td>\n",
    "        <td>\n",
    "        w2: [[-0.00322417 -0.00384054  0.01133769 -0.01099891]\n",
    " [-0.00172428 -0.00877858  0.00042214  0.00582815]]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td>\n",
    "        b1: [[ 0.]\n",
    " [ 0.]\n",
    " [ 0.]\n",
    " [ 0.]]\n",
    "        </td>\n",
    "        <td>\n",
    "b2: [[ 0.]\n",
    " [ 0.]]\n",
    " </td>\n",
    "     </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_params_deep(input_layer, hidden_layers, output_layer):\n",
    "#     np.random.seed(3) #non random random numbers (will get the same random numbers each time) used for testing\n",
    "    layers = {} #dictionary of weights and biasis\n",
    "    previous_layer = input_layer #sets the begining shape as shape of input layer\n",
    "    for i in range(len(hidden_layers)):\n",
    "        cur_layer = hidden_layers[i]\n",
    "        weights = np.random.randn(cur_layer,previous_layer)\n",
    "        weights *= .01 #because np.random.rand returns numbers too large, more efficeint durring gradient descensed \n",
    "        bias = np.zeros((cur_layer,1))\n",
    "        cur_weights_key = \"w\" + str(i + 1) # i + 1 because humans like things indexed at 0\n",
    "        cur_bias_key = \"b\" + str(i + 1)\n",
    "        layers[cur_weights_key] = weights\n",
    "        layers[cur_bias_key] = bias \n",
    "        \n",
    "        assert(layers[\"w\" + str(i + 1)].shape == (cur_layer, previous_layer))\n",
    "        assert(layers[\"b\" + str(i + 1)].shape == (cur_layer,1))\n",
    "        \n",
    "        previous_layer = cur_layer\n",
    "\n",
    "    layers[\"w\" + str(len(hidden_layers) + 1)] = np.random.randn(output_layer,previous_layer) * .01\n",
    "    layers[\"b\" + str(len(hidden_layers) + 1)] = np.zeros((output_layer,1))\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_deep2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ed6ea026f7d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparams_deep1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_params_deep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams_deep2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_deep2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params_deep2' is not defined"
     ]
    }
   ],
   "source": [
    "params_deep1 = initialize_params_deep(5,[4],3)\n",
    "for param in params_deep2:\n",
    "    print(param, params_deep2[param].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 (4, 5)\n",
      "[[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388]\n",
      " [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218]\n",
      " [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034]\n",
      " [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]\n",
      "b1 (4, 1)\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "w2 (3, 4)\n",
      "[[-0.01185047 -0.0020565   0.01486148  0.00236716]\n",
      " [-0.01023785 -0.00712993  0.00625245 -0.00160513]\n",
      " [-0.00768836 -0.00230031  0.00745056  0.01976111]]\n",
      "b2 (3, 1)\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "params_deep2 = initialize_params_deep(5,[4],3)\n",
    "for param in params_deep2:\n",
    "    print(param, params_deep2[param].shape)\n",
    "    print(params_deep2[param])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testcase initialize_params_deep \n",
    "##### seed(3) (5,[3],3)\n",
    "<table style:\"width-80%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "w1 (4, 5)\n",
    "[[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388]\n",
    " [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218]\n",
    " [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034]\n",
    " [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]\n",
    " </td>\n",
    " <td>\n",
    "b1 (4, 1)\n",
    "[[ 0.]\n",
    " [ 0.]\n",
    " [ 0.]\n",
    " [ 0.]]\n",
    "</td>\n",
    "<tr>\n",
    "<td>\n",
    "w2 (3, 4)\n",
    "[[-0.01185047 -0.0020565   0.01486148  0.00236716]\n",
    " [-0.01023785 -0.00712993  0.00625245 -0.00160513]\n",
    " [-0.00768836 -0.00230031  0.00745056  0.01976111]]\n",
    "</td>\n",
    "<td>\n",
    "b2 (3, 1)\n",
    "[[ 0.]\n",
    " [ 0.]\n",
    " [ 0.]]\n",
    " </td>\n",
    " </tr>\n",
    " </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_forward_prop(a,w,b): #a because a is from the past layer\n",
    "    w = w.T\n",
    "    a = a.T\n",
    "    z = np.dot(a,w) + b\n",
    "#     print(\"z\",z.shape,\"a\",a.shape[0],\"w\",w.shape[1],\"b\",b.shape)\n",
    "    assert(z.shape == (a.shape[0], w.shape[1] ))\n",
    "    #     assert(z.shape == np.dot(a,w).shape)\n",
    "    cached_inputs = {\"in_a\":a,\"w\":w,\"b\":b} #(a,w,b)\n",
    "    return z,cached_inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (3, 2) w (1, 3) b (1,) z (2, 1)\n",
      "[[ 3.26295337]\n",
      " [-1.23429987]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X = np.random.randn(3,2)\n",
    "w = np.random.randn(1,3)\n",
    "b = np.random.randn(1) #(1,1) broadcasting\n",
    "\n",
    "X = np.array(X)\n",
    "w = np.array(w)\n",
    "b = np.array(b)\n",
    "z,_ = linear_forward_prop(X,w,b)\n",
    "print(\"X\",X.shape,\"w\",w.shape,\"b\",b.shape,\"z\",z.shape)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test case for linear_foward_prop\n",
    "##### seed(1) x=(3,2) w=(1,3) b=(1)\n",
    "<table style:\"width-80%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "X (3, 2) w (1, 3) b (1,) z (2, 1)\n",
    "</td>\n",
    "</tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "[[ 3.26295337]\n",
    " [-1.23429987]]\n",
    " </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def singleFowardPropagation(X,w,b,activationType,leaky=0): #TODO change x to a\n",
    "#     cached_inputs = {\"w\":None,\"x\":None,\"b\":None,\"z\":None}\n",
    "    z,cached_values = linear_forward_prop(X,w,b)\n",
    "    if activationType == \"sigmoid\":\n",
    "        a, activation_cache = sigmoid(z)\n",
    "    if activationType == \"relu\":\n",
    "        a, activation_cache = relu(z,leaky=leaky)\n",
    "#     final_cache = c\n",
    "    cached_values.update(activation_cache)\n",
    "    return a, cached_values  #add asserts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relu A [[ 3.43896131]\n",
      " [ 0.        ]]\n",
      "Sigmoud A [[ 0.96890023]\n",
      " [ 0.11013289]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "X = np.random.randn(3,2)\n",
    "w = np.random.randn(1,3)\n",
    "b = np.random.randn(1,1) #(1,1) broadcasting\n",
    "a,cached_values = singleFowardPropagation(X,w,b,\"relu\")\n",
    "print(\"Relu A\",a)\n",
    "\n",
    "a,cached_values = singleFowardPropagation(X,w,b,\"sigmoid\")\n",
    "print(\"Sigmoud A\",a)\n",
    "# print(X,w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu A [[ 3.43896131]\n",
    " [ 0.        ]]\n",
    "Sigmoud A [[ 0.96890023]\n",
    " [ 0.11013289]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fowardPropagate(X,params):\n",
    "    print(\"len of params\", len(params))\n",
    "    num_layers = len(params)/2\n",
    "    #assert len params is even\n",
    "    num_layers = int(num_layers)\n",
    "    a = X\n",
    "    cached_values = []\n",
    "    for i in range(1,num_layers):\n",
    "        w = params[\"w\" + str(i)]\n",
    "        b = params[\"b\" + str(i)]\n",
    "        past_a = a\n",
    "        a, cur_cached = singleFowardPropagation(past_a,w,b,\"relu\")\n",
    "        cached_values += [cur_cached] #TODO: get foramt of cached values \n",
    "    w = params[\"w\" + len(num_layers)]\n",
    "    b = params[\"b\" + len(num_layers)]\n",
    "    a, cur_cached = singleFowardProgagation(a,w,b,\"sigmoid\")\n",
    "    cached_values += [cur_cached] \n",
    "    #write assert statemt here\n",
    "    #get shape of a at the end \n",
    "    \n",
    "    return a, cached_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w1': array([[ 0.35480861,  1.81259031, -1.3564758 , -0.46363197,  0.82465384],\n",
      "       [-1.17643148,  1.56448966,  0.71270509, -0.1810066 ,  0.53419953],\n",
      "       [-0.58661296, -1.48185327,  0.85724762,  0.94309899,  0.11444143],\n",
      "       [-0.02195668, -2.12714455, -0.83440747, -0.46550831,  0.23371059]]), 'b1': array([[ 1.38503523],\n",
      "       [-0.51962709],\n",
      "       [-0.78015214],\n",
      "       [ 0.95560959]]), 'w2': array([[-0.12673638, -1.36861282,  1.21848065, -0.85750144],\n",
      "       [-0.56147088, -1.0335199 ,  0.35877096,  1.07368134],\n",
      "       [-0.37550472,  0.39636757, -0.47144628,  2.33660781]]), 'b2': array([[ 1.50278553],\n",
      "       [-0.59545972],\n",
      "       [ 0.52834106]]), 'w3': array([[ 0.9398248 ,  0.42628539, -0.75815703]]), 'b3': array([[-0.16236698]])}\n",
      "len of params 6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (3,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-fb969e156207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mfowardPropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-b5a442cc6a28>\u001b[0m in \u001b[0;36mfowardPropagate\u001b[0;34m(X, params)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpast_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_cached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingleFowardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mcached_values\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcur_cached\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#TODO: get foramt of cached values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"w\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-e75fc4308305>\u001b[0m in \u001b[0;36msingleFowardPropagation\u001b[0;34m(X, w, b, activationType, leaky)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msingleFowardPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivationType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleaky\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#TODO change x to a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     cached_inputs = {\"w\":None,\"x\":None,\"b\":None,\"z\":None}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcached_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_forward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivationType\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-c10e0d83b8d2>\u001b[0m in \u001b[0;36mlinear_forward_prop\u001b[0;34m(a, w, b)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(\"z\",z.shape,\"a\",a.shape[0],\"w\",w.shape[1],\"b\",b.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (3,1) "
     ]
    }
   ],
   "source": [
    "np.random.seed(6)\n",
    "X = np.random.randn(5,4)\n",
    "w1 = np.random.randn(4,5)\n",
    "b1 = np.random.randn(4,1)\n",
    "w2 = np.random.randn(3,4)\n",
    "b2 = np.random.randn(3,1)\n",
    "w3 = np.random.randn(1,3)\n",
    "b3 = np.random.randn(1,1)\n",
    "params = {\n",
    "    \"w1\":w1,\n",
    "    \"b1\":b1,\n",
    "    \"w2\":w2,\n",
    "    \"b2\":b2,\n",
    "    \"w3\":w3,\n",
    "    \"b3\":b3\n",
    "}\n",
    "print(params)\n",
    "fowardPropagate(X, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linearBackprop(cached_values, dZ):\n",
    "    a = cached_values[\"in_a\"]\n",
    "    w = cached_values[\"w\"]\n",
    "    b = cached_values[\"b\"]\n",
    "    number_examples = a.shape[1]\n",
    "    dW = (1/number_examples) * np.dot(dZ,a.T)\n",
    "    dB = (1/number_examples) * np.sum(dZ, axis = 1, keepdims= True)\n",
    "    dA = np.dot(w.T, dZ)\n",
    "#write asserts for dW dB & dA TODO\n",
    "    return {\"dW\":dW,\"dB\":dB,\"dA\":dA}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dA': array([[ 0.51822968, -0.19517421],\n",
       "        [-0.40506361,  0.15255393],\n",
       "        [ 2.37496825, -0.89445391]]),\n",
       " 'dB': array([[ 0.50629448]]),\n",
       " 'dW': array([[-0.10076895,  1.40685096,  1.64992505]])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "dZ = np.random.randn(1,2)\n",
    "a = np.random.randn(3,2)\n",
    "w = np.random.randn(1,3)\n",
    "b = np.random.randn(1,1)\n",
    "cached_values = {\"w\": w, \"in_a\":a,\"b\":b}\n",
    "linearBackprop(cached_values, dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'dA': array([[ 0.51822968, -0.19517421],\n",
    "        [-0.40506361,  0.15255393],\n",
    "        [ 2.37496825, -0.89445391]]),\n",
    " 'dB': array([[ 0.50629448]]),\n",
    " 'dW': array([[-0.10076895,  1.40685096,  1.64992505]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    z = cache\n",
    "    dZ = np.array(dA, copy=True) #convert dA to np array\n",
    "    dZ[z < 0] = 0 \n",
    "    \n",
    "    return dZ\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    z = cache\n",
    "    s = 1/(1 + np.exp(-z))\n",
    "    dz = dA * s * (1-s)\n",
    "    \n",
    "    return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backwards_activation(dA, cached_values, activation_type):\n",
    "    if activation_type == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, cached_values[\"z\"])\n",
    "    if activation_type == \"relu\":\n",
    "        dZ = relu_backward(dA, cached_values[\"z\"])\n",
    "    gradients = linearBackprop(cached_values, dZ)\n",
    "    \n",
    "    return gradients\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dA': array([[ 0.44090989,  0.        ],\n",
       "        [ 0.37883606,  0.        ],\n",
       "        [-0.2298228 ,  0.        ]]),\n",
       " 'dB': array([[-0.20837892]]),\n",
       " 'dW': array([[ 0.44513824,  0.37371418, -0.10478989]])}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "dA = np.random.randn(1,2)\n",
    "a = np.random.randn(3,2)\n",
    "w = np.random.randn(1,3)\n",
    "b = np.random.randn(1,1)\n",
    "z = np.random.randn(1,2)\n",
    "cached_values = {\"w\": w, \"in_a\":a,\"b\":b, \"z\":z}\n",
    "backwards_activation(dA, cached_values, activation_type=\"relu\")\n",
    "#working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
